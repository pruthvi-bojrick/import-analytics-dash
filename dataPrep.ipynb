{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.27 s (started: 2023-01-22 16:10:04 -05:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get Data from Trade API\n",
    "\n",
    "Update the parameters as needed based on pdf in API Reference Docs Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.42 ms (started: 2023-01-22 16:10:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "## get data from 2018 to 2022-11 by HS Code, Country and District\n",
    "\n",
    "\n",
    "def getCountryDistrictValsHS(code,year,month,dirPath,comm_lvl,summ_lvl2):\n",
    "    # os.chdir(\".apiResponses\")\n",
    "    logTime = str(datetime.now().strftime(r\"%Y_%m_%d-%I_%M_%S_%p\"))\n",
    "    logging.basicConfig(filename=os.path.join(dirPath,f'{comm_lvl}_{summ_lvl2}_{code}_{logTime}_download.log'), encoding='utf-8', level=logging.DEBUG)\n",
    "    if code == 'hs':\n",
    "        base = f\"https://api.census.gov/data/timeseries/intltrade/imports/{code}\"\n",
    "        params = {\"get\":r','.join([\"I_COMMODITY\",\"I_COMMODITY_SDESC\",\"I_COMMODITY_LDESC\",\n",
    "                                \"CTY_CODE\",\"DISTRICT\",'DIST_NAME',\"RP\",\"DUT_VAL_MO\",\n",
    "                                \"CON_VAL_MO\",\"CON_QY1_MO\",\"CAL_DUT_MO\",\n",
    "                                \"GEN_CHA_MO\",\"GEN_VAL_MO\",\"GEN_CIF_MO\",\"GEN_QY1_MO\",'UNIT_QY1','CC_MO',\n",
    "                                \"CNT_CHA_MO\",\"CNT_VAL_MO\",\"CNT_WGT_MO\",\n",
    "                                \"AIR_CHA_MO\",\"AIR_VAL_MO\",\"AIR_WGT_MO\",\n",
    "                                \"VES_CHA_MO\",\"VES_VAL_MO\",\"VES_WGT_MO\"]),\n",
    "                # \"CTY_NAME\":['INDIA','CHINA','INDONESIA','VIETNAM','MEXICO','CANADA','BRAZIL','TAIWAN'],\n",
    "                \"YEAR\":year,\n",
    "                \"MONTH\":month,\n",
    "                \"COMM_LVL\":comm_lvl,\n",
    "                \"SUMMARY_LVL2\":summ_lvl2,\n",
    "                \"key\":\"f6b9d2bb24bacdbcc9bb836aa36a2c192fb902e3\"}\n",
    "        temp = requests.get(base,params=params)\n",
    "    # print(temp.url)\n",
    "    \n",
    "        df = pd.DataFrame(temp.json())\n",
    "        new_header = df.iloc[0] #grab the first row for the header\n",
    "        df = df[1:] #take the data less the header row\n",
    "        df.columns = new_header #set the header row as the df header\n",
    "\n",
    "        # df = df.drop('Unnamed: 0',axis=1)\n",
    "        df['MONTH'] = df['MONTH'].astype(str).apply(lambda x:str(x).zfill(2))\n",
    "        df['YearMonth'] = df[['YEAR','MONTH']].astype(str).agg('-'.join,axis=1)\n",
    "        if 'I_COMMODITY' in df.columns:\n",
    "            df['I_COMMODITY'] = df['I_COMMODITY'].apply(lambda x:str(x).zfill(10))\n",
    "            df['HS2'] = df['I_COMMODITY'].apply(lambda x:str(x)[:2])\n",
    "            df['HS4'] = df['I_COMMODITY'].apply(lambda x:str(x)[:4])\n",
    "            df['HS6'] = df['I_COMMODITY'].apply(lambda x:str(x)[:6])\n",
    "            df = df.rename({'I_COMMODITY':'HS10'},axis=1)\n",
    "\n",
    "# I_COMMODITY_LDESCCTY_CODE\n",
    "\n",
    "    if code == 'naics':\n",
    "        base = f\"https://api.census.gov/data/timeseries/intltrade/imports/{code}\"\n",
    "        params = {\"get\":r','.join([\"NAICS\", \"NAICS_LDESC\", \"NAICS_SDESC\", \n",
    "                                \"CTY_CODE\",'CTY_NAME',\"DISTRICT\",'DIST_NAME',\"DUT_VAL_MO\",\n",
    "                                \"CON_VAL_MO\",\"CAL_DUT_MO\",\n",
    "                               \"GEN_CHA_MO\",\"GEN_VAL_MO\",\"GEN_CIF_MO\",'CC_MO',\n",
    "                                \"CNT_CHA_MO\",\"CNT_VAL_MO\",\"CNT_WGT_MO\",\n",
    "                                \"AIR_CHA_MO\",\"AIR_VAL_MO\",\"AIR_WGT_MO\",\n",
    "                                \"VES_CHA_MO\",\"VES_VAL_MO\",\"VES_WGT_MO\"]),\n",
    "                # \"CTY_NAME\":['INDIA','CHINA','INDONESIA','VIETNAM','MEXICO','CANADA','BRAZIL'],\n",
    "                \"YEAR\":year,\n",
    "                \"MONTH\":month,\n",
    "                \"COMM_LVL\":comm_lvl,\n",
    "                \"SUMMARY_LVL2\":summ_lvl2,\n",
    "                \"key\":\"f6b9d2bb24bacdbcc9bb836aa36a2c192fb902e3\"}\n",
    "        temp = requests.get(base,params=params)\n",
    "    # print(temp.url)\n",
    "    \n",
    "        df = pd.DataFrame(temp.json())\n",
    "        new_header = df.iloc[0] #grab the first row for the header\n",
    "        df = df[1:] #take the data less the header row\n",
    "        df.columns = new_header #set the header row as the df header\n",
    "\n",
    "        # df = df.drop('Unnamed: 0',axis=1)\n",
    "        df['MONTH'] = df['MONTH'].astype(str).apply(lambda x:str(x).zfill(2))\n",
    "        df['YearMonth'] = df[['YEAR','MONTH']].astype(str).agg('-'.join,axis=1)\n",
    "\n",
    "        if 'NACIS' in df.columns:\n",
    "            df['NAICS'] = df['NAICS'].apply(lambda x:str(x).zfill(6))\n",
    "            df['NA2'] = df['NACIS'].apply(lambda x:str(x)[:2])\n",
    "            df['NA4'] = df['NACIS'].apply(lambda x:str(x)[:4])\n",
    "            df = df.rename({'NACIS':'NA6'},axis=1)\n",
    "\n",
    "    \n",
    "    fileName = f\"{dirPath}/{code}/{params['COMM_LVL']}_{params['SUMMARY_LVL2']}_{year}_{month}.gzip\"\n",
    "    \n",
    "    df.to_csv(fileName, compression='gzip',index=False)\n",
    "    logging.info(f\"{logTime}_{df.shape} rows,columns saved.! {df.memory_usage().sum()/1e6}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms (started: 2023-01-22 16:10:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "years = [str(year) for year in range(2019,2022)]\n",
    "months = [str(month).zfill(2) for month in range(1,13)]\n",
    "yearMonthFilter = [tuple([year,month])for year in years for month in months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2019', '01'),\n",
       " ('2019', '02'),\n",
       " ('2019', '03'),\n",
       " ('2019', '04'),\n",
       " ('2019', '05'),\n",
       " ('2019', '06'),\n",
       " ('2019', '07'),\n",
       " ('2019', '08'),\n",
       " ('2019', '09'),\n",
       " ('2019', '10'),\n",
       " ('2019', '11'),\n",
       " ('2019', '12'),\n",
       " ('2020', '01'),\n",
       " ('2020', '02'),\n",
       " ('2020', '03'),\n",
       " ('2020', '04'),\n",
       " ('2020', '05'),\n",
       " ('2020', '06'),\n",
       " ('2020', '07'),\n",
       " ('2020', '08'),\n",
       " ('2020', '09'),\n",
       " ('2020', '10'),\n",
       " ('2020', '11'),\n",
       " ('2020', '12'),\n",
       " ('2021', '01'),\n",
       " ('2021', '02'),\n",
       " ('2021', '03'),\n",
       " ('2021', '04'),\n",
       " ('2021', '05'),\n",
       " ('2021', '06'),\n",
       " ('2021', '07'),\n",
       " ('2021', '08'),\n",
       " ('2021', '09'),\n",
       " ('2021', '10'),\n",
       " ('2021', '11'),\n",
       " ('2021', '12')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 ms (started: 2023-01-22 16:10:10 -05:00)\n"
     ]
    }
   ],
   "source": [
    "yearMonthFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [2:51:05<00:00, 106.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2h 51min 5s (started: 2023-01-22 01:11:33 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year,month in tqdm(yearMonthFilter):\n",
    "    getCountryDistrictValsHS(code='naics',\n",
    "                            year=year,\n",
    "                            month=month,\n",
    "                            dirPath='.apiResponses',\n",
    "                            comm_lvl='NA6',\n",
    "                            summ_lvl2='NACYDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [01:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m year,month \u001b[39min\u001b[39;00m tqdm(yearMonthFilter):\n\u001b[0;32m----> 2\u001b[0m     getCountryDistrictValsHS(code\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhs\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                             year\u001b[39m=\u001b[39;49myear,\n\u001b[1;32m      4\u001b[0m                             month\u001b[39m=\u001b[39;49mmonth,\n\u001b[1;32m      5\u001b[0m                             dirPath\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.apiResponses\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                             comm_lvl\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHS10\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                             summ_lvl2\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHSCYDT\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mgetCountryDistrictValsHS\u001b[0;34m(code, year, month, dirPath, comm_lvl, summ_lvl2)\u001b[0m\n\u001b[1;32m      9\u001b[0m     base \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.census.gov/data/timeseries/intltrade/imports/\u001b[39m\u001b[39m{\u001b[39;00mcode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39m\"\u001b[39m\u001b[39mI_COMMODITY\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mI_COMMODITY_SDESC\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mI_COMMODITY_LDESC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mCTY_CODE\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mDISTRICT\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDIST_NAME\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mRP\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mDUT_VAL_MO\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mCON_VAL_MO\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mCON_QY1_MO\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mCAL_DUT_MO\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCOMM_LVL\u001b[39m\u001b[39m\"\u001b[39m:comm_lvl,\n\u001b[1;32m     21\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSUMMARY_LVL2\u001b[39m\u001b[39m\"\u001b[39m:summ_lvl2}\n\u001b[0;32m---> 22\u001b[0m     temp \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(base,params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m     23\u001b[0m \u001b[39m# print(temp.url)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(temp\u001b[39m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/urllib3/response.py:831\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_chunk(amt)\n\u001b[1;32m    832\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(\n\u001b[1;32m    833\u001b[0m     chunk, decode_content\u001b[39m=\u001b[39mdecode_content, flush_decoder\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    834\u001b[0m )\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m decoded:\n",
      "File \u001b[0;32m~/ProjectRepos/import-analytics-dash/.dashenv/lib64/python3.11/site-packages/urllib3/response.py:775\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39melif\u001b[39;00m amt \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left:\n\u001b[0;32m--> 775\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49m_safe_read(amt)\n\u001b[1;32m    776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m-\u001b[39m amt\n\u001b[1;32m    777\u001b[0m     returned_chunk \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m/usr/lib64/python3.11/http/client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_read\u001b[39m(\u001b[39mself\u001b[39m, amt):\n\u001b[1;32m    624\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[1;32m    626\u001b[0m \u001b[39m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[1;32m    632\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/usr/lib64/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib64/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 10s (started: 2023-01-22 16:17:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "for year,month in tqdm(yearMonthFilter):\n",
    "    getCountryDistrictValsHS(code='hs',\n",
    "                            year=year,\n",
    "                            month=month,\n",
    "                            dirPath='.apiResponses',\n",
    "                            comm_lvl='HS10',\n",
    "                            summ_lvl2='HSCYDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dashenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e25057c6014c70833d5c6fa785354358ed0334dfa55da4dba0c885d6c054fdb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
